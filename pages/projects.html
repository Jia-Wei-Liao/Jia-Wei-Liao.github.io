<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Jiawei</title>
    <link rel="icon" href="../images/logo.png" type="image/x-icon" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link href="../css/style.css" rel="stylesheet">
  </head>
  <body>
    <div class="navigation-container">
      <div class="navigation-text">
        <h3><a href="../index.html" class="website-name"><b>Jia-Wei Liao</b></a></h3>
        <div class="navigation-list">
          <a href="./awards.html">Awards</a>
          <a href="./projects.html"><b>Projects</b></a>
          <a href="./activities.html">Activities</a>
          <a href="./teaching.html">Teachings</a>
          <a href="../files/cv.pdf">CV</a>
        </div>
      </div>
    </div>
    <div class="website-container">
      <h2 style="text-align:center;">PROJECTS</h2>
      <div class="project-container">
        <div style="width: 20%; align-self: center;">
          <img src="../images/SOA-img0012_1332_0_2164_832.jpeg" width="140"; />
        </div>
        <div style="width: 80%;">
          <h5><b>A Small Object Detection Framework for Unmanned Aerial Vehicles Images</b></h5>
          <p>
            Jing-En Huang, and <b>Jia-Wei Liao</b>, <i>AI CUP</i>, 2022
            <a href="../files/uav_object_detection_report.pdf"><i class="fa fa-file" style="color:#000000"></i></a>
          </p>
          <p>We developed a state-of-the-art one-stage detection model as the baseline framework for the competition, with the goal of accurately detecting small objects. To enhance performance, we utilized data relabeling, super-resolution, and a small object augmentation algorithm. Additionally, we employed the sliding window technique to reduce computation complexity and improve training speed. Post-processing techniques such as TTA, NMS, and WBF were also implemented to further improve model performance. As a result, we achieved a top 5 ranking in the competition with a public score of 0.7394 and a private score of 0.7550.</p>
        </div>
      </div>
      <br/>
      <div class="project-container">
        <div style="width: 20%; align-self: center;">
          <img src="../images/crop_cam.png" width="140"; />
        </div>
        <div style="width: 80%;">
          <h5><b>Crop Image Recognition</b></h5>
          <p>
            <b>Jia-Wei Liao</b>, Yen-Jia Chen, Yi-Cheng Hung, Jing-En Hung, and Shang-Yen Lee, <i>AI CUP</i>, 2022
            <a href="https://github.com/Jia-Wei-Liao/Crop_Classification" style="color:#000000"><i class="fab fa-github"></i></a>
            <a href="../files/crop_image_recognition_report.pdf" style="color:#000000"><i class="fa fa-file"></i></a>
          </p>
          <p>We explored various models, applied auto-augmentation techniques to diversify the dataset, and trained with CNN base models like EfficientNet and Transformer-base models like Swin. Our results showed that using SGD as the optimizer had better convergence than AdamW and higher image resolution led to better training performance. We found that the Swin model performed better on lower resolution data while CNN base models performed better on high resolution data. To evaluate the stability and advantage of ensemble combination, we applied TTA and ensemble to both public and private datasets. As a result, we achieved a public ranking of 9th and a private ranking of 8th, with scores of 0.9329 and 0.9344 respectively.</p>
        </div>
      </div>
      <br/>   
      <div class="project-container">
        <div style="width: 20%; align-self: center;">
          <img src="../images/t5.png" width="140"; />
        </div>
        <div style="width: 80%;">
          <h5><b>Interpretive Information Labeling for Natural Language Processing</b></h5>
          <p>
            <b>Jia-Wei Liao</b>, Jung-Mei Chu, and Chia-Chi Huang, <i>AI CUP</i>, 2022
            <a href="https://github.com/Jia-Wei-Liao/Interpretive_Information_Labeling_for_NLP" style="color:#000000"><i class="fab fa-github"></i></a>
          </p>
          <p>We constructed an explainable deep learning model for a NLP task by converting it into a summary task. Initially we used a LSTM model but switched to T5 with pretrained weights to achieve better results. We applied the T5 model to two datasets with different pre-processing methods and surpassed the original data's baseline. We achieved a public score of 0.801772 and a private score of 0.85190.</p>
        </div>
      </div>
      <br/>    
      <div class="project-container">
        <div style="width: 20%; align-self: center;">
          <img src="../images/stas.jpg" width="140"; />
        </div>
        <div style="width: 80%;">
          <h5><b>Contour Segmentation for Spread Through Air Spaces in Lung Adenocarcinoma</b></h5>
          <p>
            Kuok-Tong Ng, <b>Jia-Wei Liao</b>, and Yi-Cheng Hung, <i>AI CUP</i>, 2022
            <a href="https://github.com/Jia-Wei-Liao/Spread_Through_Air_Spaces_Segmentation" style="color:#000000"><i class="fab fa-github"></i></a>
          </p>
          <p>We developed a UNet-based model with a diverse backbone, addressing the imbalance of foreground and background through a combination of DiceLoss and Focal Loss, and enhancing robustness through auto-augmentation. Our post-processing strategies improved accuracy, resulting in a 3rd place public ranking and 16th place private ranking, with scores of 0.9194 and 0.9109 respectively.</p>
        </div>
      </div>
      <br/>
      <div class="project-container">
        <div style="width: 20%; align-self: center;">
          <img src="../images/orchids.png" width="140"; />
        </div>
        <div style="width: 80%;">
          <h5><b>Supervised Learning for Few-Shot Orchid types Classification with Prior Guided Feature</b></h5>
          <p>
            Yu-Hsi Chen, <b>Jia-Wei Liao</b>, and Kuok-Tong Ng, <i>AI CUP</i>, 2022
            <a href="https://github.com/Jia-Wei-Liao/Few-Shot_Orchid_types_Classification" style="color:#000000"><i class="fab fa-github"></i></a>
          </p>
          <p>We develop a non-artificial method for accurately distinguishing orchids with similar appearances. Orchids are a diverse group of plants with over 20,000 species found in various ecological environments, except for extreme climates. However, advancements in biotechnology have led to the creation of similar new species, making it difficult for experts to distinguish them. Due to the lack of training data, we employed a few-shot learning approach to transfer information from one task and generalize to a new task with a small amount of data. We used various models, data augmentation methods, training objective functions, optimization methods, and learning rate schedules in our approach. After multiple trials, we ensemble the six predictions with the highest accuracy to obtain the final predictions. Our method achieved a Marco-F1 score of 0.9115 and 0.8096 on public and private datasets, respectively, and ranked 15th out of 743 teams in the competition.</p>
        </div>
      </div>
      <br/>    
      <div class="project-container">
        <div style="width: 20%; align-self: center;">
          <img src="../images/land_segmentation.png" width="140"; />
        </div>
        <div style="width: 80%;">
          <h5><b>MediaTek Low-power Segmentation Competition</b></h5>
          <p>
            Jia-Wei Liao, <i>Machine Learning Final Project</i>, 2022
            <a href="https://github.com/Jia-Wei-Liao/MediaTek_LowPower_Semantic_Segmentation" style="color:#000000"><i class="fab fa-github"></i></a>
          </p>
          <p>We propose a lightweight deep learning-based semantic segmentation model that is suitable for constrained embedded systems and is optimized for traffic scene analysis in Asian countries, such as Taiwan. The model focuses on improving segmentation accuracy, reducing power consumption, and achieving real-time performance. The model is also designed to be deployed on MediaTek's Dimensity Series platform. The evaluation metric used is mean Intersection over Union (mIoU) which is a widely used metric for multi-class semantic segmentation tasks. Our experiments yielded a test public score of 0.5624.</p>
        </div>
      </div>
      <br/>
      <div class="project-container">
        <div style="width: 20%; align-self: center;">
          <img src="../images/ultrasound_nerve_segmentation.png" width="140"; />
        </div>
        <div style="width: 80%;">
          <h5><b>Ultrasound Nerve Segmentation</b></h5>
          <p>
            <b>Jia-Wei Liao</b>, Kuok-Tong Ng, and Yi-Cheng Hung, <i>VRDL Final Project (Kaggle)</i>, 2021
            <a href="https://github.com/Jia-Wei-Liao/Ultrasound_Nerve_Segmentation" style="color:#000000"><i class="fab fa-github"></i></a>
            <a href="../files/ultrasound_nerve_segmentation_report.pdf" style="color:#000000"><i class="fa fa-file-powerpoint"></i></a>
            <a href="https://www.youtube.com/watch?v=WTO3IVHHfkU&list=PL0kyR2GxfvqhvyAuFyLhGWa_tOHLOYWQ6&index=67"><i class="fab fa-youtube" style="color: red"></i></a></li>
          </p>
          <p>We present a deep learning-based approach for ultrasound nerve segmentation using the UNet architecture with the EfficientNet backbone. Two novel methods, Erosion Mask Smoothing (ELS) and adaptive Single Model Ensemble (ASME) were proposed to improve the segmentation performance. The evaluation metric used is the Dice Similarity Coefficient (DSC), and the results show that the proposed approach outperforms the baseline with a test private score of 0.7234, achieved through the use of ASME.</p>
        </div>
      </div>
      <br/> 
      <div class="project-container">
        <div style="width: 20%; align-self: center;">
          <img src="../images/netflix.jpeg" width="140"; />
        </div>
        <div style="width: 80%;">
          <h5><b>Recommender System using Matrix Factorization</b></h5>
          <p>
            <b>Jia-Wei Liao</b>, Kuok-Tong Ng, and Yi-Cheng Hung, <i>Introduction to Scientific Computing Final Project</i>, 2021
            <a href="https://github.com/Jia-Wei-Liao/Low-rank_Matrix_Approximation_for_Recommender_System" style="color:#000000"><i class="fab fa-github"></i></a>
            <a href="../files/recommender_system_using_matrix_factorization_slides.pdf" style="color:#000000"><i class="fa fa-file-powerpoint"></i></a>
          </p>
        </div>
      </div>
      <br/>
      <div class="project-container">
        <div style="width: 20%; align-self: center;">
          <img src="../images/yelp.png" width="140"; />
        </div>
        <div style="width: 80%;">
          <h5><b>Sentiment Analysis of Food Reviews on Yelp Platform</b></h5>
          <p>
            <b>Jia-Wei Liao</b>, Yi-Cheng Hung, and Yu-Lin Tsai, <i>Introduction to Data Science Final Project</i>, 2021
            <a href="https://github.com/Jia-Wei-Liao/NLP_for_Yelp_Dataset" style="color:#000000"><i class="fab fa-github"></i></a>
            <a href="../files/sentiment_analysis_of_food_reviews_on_yelp_platform.pdf" style="color:#000000"><i class="fa fa-file-powerpoint"></i></a>
          </p>
        </div>
      </div>
      <br/>   
      <div class="project-container">
        <div style="width: 20%; align-self: center;">
          <img src="../images/noise.png" width="140"; />
        </div>
        <div style="width: 80%;">
          <h5><b>Mean Curvature Flow on Graphs for Image Denoising</b></h5>
          <p>
            <b>Jia-Wei Liao</b>, and Kuok-Tong Ng, <i>Image Processing with Partial Differential Equations Final Project</i>, 2020
            <a href="https://github.com/Jia-Wei-Liao/Mean_Curvature_Flow_on_Graphs_for_Image_Denoising" style="color:#000000"><i class="fab fa-github"></i></a>
          </p>
        </div>
      </div>
      <br/>
      <div class="project-container">
        <div style="width: 20%; align-self: center;">
          <img src="../images/inpainting.png" width="140"; />
        </div>
        <div style="width: 80%;">
          <h5><b>Sparse Dictionary Learning for Image Inpainting</b></h5>
          <p>
            <b>Jia-Wei Liao</b>, and Kuok-Tong Ng, <i>Optimization for Data Science Final Project</i>, 2020
            <a href="https://github.com/Jia-Wei-Liao/Sparse_Dictionary_Learning_for_Image_Inpainting" style="color:#000000"><i class="fab fa-github"></i></a>
            <a href="../files/sparse_dictionary_learning_for_image_inpainting_slides.pdf" style="color:#000000"><i class="fa fa-file-powerpoint"></i></a>
          </p>
        </div>
      </div>
      <br/>
    </div>
  </body>
</html>
